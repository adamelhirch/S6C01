{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SAE-75: TF-IDF Vectorization Demo\n",
                "\n",
                "Ce notebook démontre l'utilisation de la fonction `compute_tfidf` pour vectoriser les reviews Yelp."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import sys\n",
                "import os\n",
                "\n",
                "# Ajouter le dossier src au path\n",
                "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
                "\n",
                "from src.features import compute_tfidf\n",
                "from src.text_preprocessing import preprocess_text"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Chargement des données"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Charger un échantillon de reviews\n",
                "DATA_PATH = '../../data/cleaned/reviews_clean.parquet'\n",
                "\n",
                "try:\n",
                "    df = pd.read_parquet(DATA_PATH)\n",
                "    # Échantillonner pour la démo\n",
                "    df_sample = df.sample(n=1000, random_state=42)\n",
                "    print(f\"Loaded {len(df_sample)} reviews.\")\n",
                "except FileNotFoundError:\n",
                "    print(f\"File not found: {DATA_PATH}\")\n",
                "    # Fallback si exécuté depuis la racine\n",
                "    DATA_PATH = 'data/cleaned/reviews_clean.parquet'\n",
                "    df = pd.read_parquet(DATA_PATH)\n",
                "    df_sample = df.sample(n=1000, random_state=42)\n",
                "    print(f\"Loaded {len(df_sample)} reviews (fallback path).\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Preprocessing (si nécessaire)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if 'text_preprocessed' not in df_sample.columns:\n",
                "    print(\"Pre-processing text...\")\n",
                "    df_sample['text_preprocessed'] = df_sample['text'].apply(lambda x: preprocess_text(str(x)))\n",
                "    print(\"Preprocessing done.\")\n",
                "else:\n",
                "    print(\"Using existing preprocessed text.\")\n",
                "\n",
                "print(df_sample[['text', 'text_preprocessed']].head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. TF-IDF Vectorization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Application de TF-IDF\n",
                "tfidf_matrix, vectorizer = compute_tfidf(\n",
                "    df_sample['text_preprocessed'], \n",
                "    max_features=1000, \n",
                "    stop_words='english',  # Utilisation de **kwargs\n",
                "    ngram_range=(1, 2)     # Utilisation de **kwargs\n",
                ")\n",
                "\n",
                "print(f\"TF-IDF Matrix Shape: {tfidf_matrix.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Analyse des résultats"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Récupérer les noms des features\n",
                "feature_names = vectorizer.get_feature_names_out()\n",
                "\n",
                "# Somme des scores TF-IDF pour chaque terme\n",
                "tfidf_sum = tfidf_matrix.sum(axis=0)\n",
                "\n",
                "# Créer un DataFrame pour visualiser\n",
                "tfidf_scores = pd.DataFrame(\n",
                "    tfidf_sum.T,\n",
                "    index=feature_names,\n",
                "    columns=['score']\n",
                ").sort_values('score', ascending=False)\n",
                "\n",
                "print(\"Top 20 termes les plus importants (par score cumulé) :\")\n",
                "print(tfidf_scores.head(20))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
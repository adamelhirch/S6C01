{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAE-76 - TF-IDF Optimis√©\n",
    "\n",
    "**En tant que** ML engineer  \n",
    "**Je veux** optimiser les param√®tres TF-IDF  \n",
    "**Afin de** am√©liorer la qualit√© de la repr√©sentation\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "- Explorer les param√®tres (max_features, min_df, max_df, ngrams)\n",
    "- Comparer diff√©rentes configurations\n",
    "- S√©lectionner la meilleure configuration\n",
    "- Sauvegarder le mod√®le optimal\n",
    "\n",
    "## Input/Output\n",
    "\n",
    "- **Input**: `data/cleaned/reviews_text_cleaned.parquet`\n",
    "- **Output**: `outputs/models/tfidf_vectorizer.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"‚úÖ Imports r√©ussis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration des chemins\n",
    "DATA_PATH = Path('../../data/cleaned/reviews_text_cleaned.parquet')\n",
    "MODEL_PATH = Path('../../outputs/models/tfidf_vectorizer.pkl')\n",
    "\n",
    "# Cr√©er le dossier output si n√©cessaire\n",
    "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÇ Chargement: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des donn√©es\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "print(f\"‚úÖ Donn√©es charg√©es: {len(df):,} reviews\")\n",
    "\n",
    "# V√©rification de la colonne text_cleaned\n",
    "if 'text_cleaned' not in df.columns:\n",
    "    raise KeyError(\"‚ùå La colonne 'text_cleaned' est manquante!\")\n",
    "\n",
    "# Remplir les NaNs potentiels\n",
    "df['text_cleaned'] = df['text_cleaned'].fillna('')\n",
    "\n",
    "# Aper√ßu\n",
    "df[['text_cleaned']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploration et Comparaison des Configurations\n",
    "\n",
    "Nous allons tester 3 configurations:\n",
    "1. **Default**: Param√®tres par d√©faut\n",
    "2. **Limited**: Vocabulaire limit√© (max_features=5000, min_df=5, max_df=0.8)\n",
    "3. **Bigrams**: Unigrams + Bigrams avec vocabulaire limit√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition des vectorizers\n",
    "vectorizers = {\n",
    "    \"Default\": TfidfVectorizer(),\n",
    "    \"Limited\": TfidfVectorizer(\n",
    "        max_features=5000,\n",
    "        min_df=5,\n",
    "        max_df=0.8\n",
    "    ),\n",
    "    \"Bigrams\": TfidfVectorizer(\n",
    "        max_features=5000,\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=5\n",
    "    )\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"üöÄ D√©but de la comparaison...\")\n",
    "\n",
    "for name, vect in vectorizers.items():\n",
    "    print(f\"\\n‚è≥ Traitement config: {name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Fit transform\n",
    "    X = vect.fit_transform(df['text_cleaned'])\n",
    "    \n",
    "    # Calculs m√©triques\n",
    "    sparsity = (1 - X.nnz / (X.shape[0] * X.shape[1])) * 100\n",
    "    vocab_size = len(vect.get_feature_names_out())\n",
    "    memory_mb = X.data.nbytes / (1024 * 1024)\n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    print(f\"   ‚úÖ Termin√© en {duration:.2f}s\")\n",
    "    print(f\"   üìä Shape: {X.shape}\")\n",
    "    print(f\"   üìö Vocab size: {vocab_size:,}\")\n",
    "    print(f\"   üï∏Ô∏è Sparsity: {sparsity:.4f}%\")\n",
    "    \n",
    "    results.append({\n",
    "        'Configuration': name,\n",
    "        'Vocab Size': vocab_size,\n",
    "        'Sparsity (%)': sparsity,\n",
    "        'Memory (MB)': memory_mb,\n",
    "        'Time (s)': duration\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le tableau comparatif\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nüèÜ R√©sultats Comparatifs:\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyse et Choix\n",
    "\n",
    "### Analyse des r√©sultats\n",
    "- **Default**: Vocabulaire tr√®s large, risque de bruit et d'overfitting. Lent.\n",
    "- **Limited**: Vocabulaire contr√¥l√©, plus rapide, focus sur les mots fr√©quents.\n",
    "- **Bigrams**: Capture des contextes (ex: \"not good\"), vocabulaire contr√¥l√© par max_features.\n",
    "\n",
    "### Choix Final\n",
    "Nous choisissons la configuration **Bigrams** car elle permet de capturer plus de sens (n√©gation, superlatifs compos√©s) tout en gardant une dimensionnalit√© g√©rable (5000 features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sauvegarde du Meilleur Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = \"Bigrams\"\n",
    "best_vectorizer = vectorizers[best_model_name]\n",
    "\n",
    "print(f\"üíæ Sauvegarde du mod√®le '{best_model_name}' vers {MODEL_PATH}...\")\n",
    "\n",
    "with open(MODEL_PATH, 'wb') as f:\n",
    "    pickle.dump(best_vectorizer, f)\n",
    "\n",
    "print(\"‚úÖ Mod√®le sauvegard√© avec succ√®s!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification du chargement\n",
    "with open(MODEL_PATH, 'rb') as f:\n",
    "    loaded_vect = pickle.load(f)\n",
    "\n",
    "print(f\"üîç V√©rification rechargement: {type(loaded_vect)}\")\n",
    "print(f\"   Params: ngram_range={loaded_vect.ngram_range}, max_features={loaded_vect.max_features}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

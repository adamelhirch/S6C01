{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Embeddings (Word2Vec Average)\n",
    "\n",
    "Objectif: Créer une représentation vectorielle fixe pour chaque document (review) en moyennant les vecteurs de ses mots.\n",
    "\n",
    "Partie de la story **SAE-78**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T09:46:40.714593Z",
     "iopub.status.busy": "2026-02-06T09:46:40.713595Z",
     "iopub.status.idle": "2026-02-06T09:46:42.776990Z",
     "shell.execute_reply": "2026-02-06T09:46:42.775125Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Enable tqdm for pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des Données et du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T09:46:42.781506Z",
     "iopub.status.busy": "2026-02-06T09:46:42.780000Z",
     "iopub.status.idle": "2026-02-06T09:46:42.868498Z",
     "shell.execute_reply": "2026-02-06T09:46:42.867944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../../outputs/reviews_preprocessed.pkl...\n",
      "Loaded 2000 reviews.\n",
      "Loading model from ../../outputs/models/word2vec_yelp.model...\n",
      "Model loaded. Vector size: 100\n"
     ]
    }
   ],
   "source": [
    "preprocessed_path = '../../outputs/reviews_preprocessed.pkl'\n",
    "model_path = '../../outputs/models/word2vec_yelp.model'\n",
    "\n",
    "# 1. Load Data\n",
    "if os.path.exists(preprocessed_path):\n",
    "    print(f\"Loading data from {preprocessed_path}...\")\n",
    "    reviews = pd.read_pickle(preprocessed_path)\n",
    "    print(f\"Loaded {len(reviews)} reviews.\")\n",
    "else:\n",
    "    print(\"Error: Preprocessed data not found. Please run SAE-74 notebook first.\")\n",
    "    # Fallback to empty for structure check\n",
    "    reviews = pd.DataFrame({'tokens_final': [['good', 'food'], ['bad']]})\n",
    "\n",
    "# 2. Load Model\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = Word2Vec.load(model_path)\n",
    "    print(f\"Model loaded. Vector size: {model.vector_size}\")\n",
    "else:\n",
    "    print(\"Error: Model not found. Please run SAE-77 notebook first.\")\n",
    "    # Dummy model for structure check\n",
    "    from gensim.models import Word2Vec\n",
    "    model = Word2Vec(sentences=[['test']], vector_size=100, min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul des Document Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T09:46:42.896802Z",
     "iopub.status.busy": "2026-02-06T09:46:42.896802Z",
     "iopub.status.idle": "2026-02-06T09:46:43.145879Z",
     "shell.execute_reply": "2026-02-06T09:46:43.145339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating document embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing vectors:   0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing vectors:  46%|████▌     | 923/2000 [00:00<00:00, 9203.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing vectors:  92%|█████████▏| 1844/2000 [00:00<00:00, 9108.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing vectors: 100%|██████████| 2000/2000 [00:00<00:00, 9132.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document Embeddings Shape: (2000, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def document_vector_mean(tokens, model):\n",
    "    \"\"\"\n",
    "    Calculate the mean of word vectors for a document.\n",
    "    \n",
    "    Args:\n",
    "        tokens (list): List of tokens in the document.\n",
    "        model (Word2Vec): Trained Word2Vec model.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.array: Mean vector (size: model.vector_size).\n",
    "    \"\"\"\n",
    "    # Filter tokens present in the model's vocabulary\n",
    "    vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
    "    \n",
    "    if len(vectors) == 0:\n",
    "        # Return zero vector if no words in vocab\n",
    "        return np.zeros(model.vector_size)\n",
    "    \n",
    "    # Calculate mean\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "print(\"Calculating document embeddings...\")\n",
    "# Apply to all reviews\n",
    "doc_vectors = np.array([\n",
    "    document_vector_mean(tokens, model) \n",
    "    for tokens in tqdm(reviews['tokens_final'], desc=\"Computing vectors\")\n",
    "])\n",
    "\n",
    "print(f\"\\nDocument Embeddings Shape: {doc_vectors.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T09:46:43.148887Z",
     "iopub.status.busy": "2026-02-06T09:46:43.148887Z",
     "iopub.status.idle": "2026-02-06T09:46:43.161181Z",
     "shell.execute_reply": "2026-02-06T09:46:43.160629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First document vector sample: [-0.02792758  0.10660151  0.00516811 -0.02206274 -0.00614953 -0.31578484\n",
      "  0.08371179  0.2872118  -0.20687567 -0.08231399]\n",
      "Number of zero vectors: 0 / 2000\n"
     ]
    }
   ],
   "source": [
    "# Check first vector\n",
    "print(\"First document vector sample:\", doc_vectors[0][:10])\n",
    "\n",
    "# Check for zero vectors (documents with no known words)\n",
    "zero_vectors_count = np.sum(np.all(doc_vectors == 0, axis=1))\n",
    "print(f\"Number of zero vectors: {zero_vectors_count} / {len(doc_vectors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T09:46:43.162693Z",
     "iopub.status.busy": "2026-02-06T09:46:43.162693Z",
     "iopub.status.idle": "2026-02-06T09:46:43.176711Z",
     "shell.execute_reply": "2026-02-06T09:46:43.176113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document embeddings saved to ../../outputs\\doc_embeddings_w2v.npy\n"
     ]
    }
   ],
   "source": [
    "output_dir = '../../outputs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'doc_embeddings_w2v.npy')\n",
    "\n",
    "np.save(output_path, doc_vectors)\n",
    "print(f\"Document embeddings saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

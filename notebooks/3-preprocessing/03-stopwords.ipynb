{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suppression des Stopwords\n",
    "\n",
    "Objectif: Supprimer les mots courants (stopwords) tout en gardant les mots importants pour le contexte (comme la négation).\n",
    "\n",
    "Partie de la story **SAE-72**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T08:45:49.703829Z",
     "iopub.status.busy": "2026-02-06T08:45:49.703829Z",
     "iopub.status.idle": "2026-02-06T08:45:51.616427Z",
     "shell.execute_reply": "2026-02-06T08:45:51.616427Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\melou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\melou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.abspath(os.path.join('../..', 'src')))\n",
    "\n",
    "from text_preprocessing import tokenize_text, remove_stopwords\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T08:45:51.636386Z",
     "iopub.status.busy": "2026-02-06T08:45:51.636386Z",
     "iopub.status.idle": "2026-02-06T08:45:54.536187Z",
     "shell.execute_reply": "2026-02-06T08:45:54.535489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 999985 reviews\n",
      "Using sample of 1000 reviews\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned reviews\n",
    "reviews_path = '../../data/cleaned/reviews_clean.parquet'\n",
    "if os.path.exists(reviews_path):\n",
    "    reviews = pd.read_parquet(reviews_path)\n",
    "    print(f\"Loaded {len(reviews)} reviews\")\n",
    "    \n",
    "    # Use a sample for speed\n",
    "    reviews = reviews.head(1000).copy()\n",
    "    print(\"Using sample of 1000 reviews\")\n",
    "else:\n",
    "    print(\"Data file not found. Creating dummy data.\")\n",
    "    # Create text with negations to test our features\n",
    "    reviews = pd.DataFrame({'text': [\n",
    "        \"The food is not good at all.\",\n",
    "        \"This is no doubt the best place.\",\n",
    "        \"I will not be returning.\",\n",
    "        \"Service was great and fast.\"\n",
    "    ]})\n",
    "\n",
    "# Apply tokenization first (SAE-71)\n",
    "reviews['tokens'] = reviews['text'].apply(str).apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: Suppression Standard vs Conservation Négation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T08:45:54.538204Z",
     "iopub.status.busy": "2026-02-06T08:45:54.538204Z",
     "iopub.status.idle": "2026-02-06T08:45:54.582019Z",
     "shell.execute_reply": "2026-02-06T08:45:54.581341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords removal applied.\n"
     ]
    }
   ],
   "source": [
    "# Standard removal\n",
    "reviews['tokens_clean_standard'] = reviews['tokens'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "# Removal preserving negation\n",
    "negation_words = {'no', 'not', 'nor', 'neither'}\n",
    "reviews['tokens_clean_negation'] = reviews['tokens'].apply(lambda x: remove_stopwords(x, exclude=negation_words))\n",
    "\n",
    "print(\"Stopwords removal applied.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T08:45:54.584045Z",
     "iopub.status.busy": "2026-02-06T08:45:54.584045Z",
     "iopub.status.idle": "2026-02-06T08:45:54.612963Z",
     "shell.execute_reply": "2026-02-06T08:45:54.612289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texte Original: Went for lunch and found that my burger was meh. What was obvious was that the focus of the burgers is the amount of different and random crap they can pile on it and not the flavor of the meat. My burger patty seemed steamed and appeared to be a preformed patty, contrary to what is stated on the menu. I can get ground beef from Kroger and make a burger that blows them out of the water.\n",
      "Standard Clean: ['Went', 'lunch', 'found', 'burger', 'meh', '.', 'obvious', 'focus', 'burgers', 'amount', 'different', 'random', 'crap', 'pile', 'flavor', 'meat', '.', 'burger', 'patty', 'seemed', 'steamed', 'appeared', 'preformed', 'patty', ',', 'contrary', 'stated', 'menu', '.', 'get', 'ground', 'beef', 'Kroger', 'make', 'burger', 'blows', 'water', '.']\n",
      "Keep Negation : ['Went', 'lunch', 'found', 'burger', 'meh', '.', 'obvious', 'focus', 'burgers', 'amount', 'different', 'random', 'crap', 'pile', 'not', 'flavor', 'meat', '.', 'burger', 'patty', 'seemed', 'steamed', 'appeared', 'preformed', 'patty', ',', 'contrary', 'stated', 'menu', '.', 'get', 'ground', 'beef', 'Kroger', 'make', 'burger', 'blows', 'water', '.']\n",
      "\n",
      "Texte Original: Dirt cheap happy hour specials. Half priced drinks. Not really my crowd. Lots of college kids on a Saturday night. On the other hand there were lots of hot girls. YEAAAHHH buddy! I'll get to the point. As hard as they really try to turn this place into a club at nights it will still and always be a tavern. The bartender was nice but they charged me full price on drinks 5-10 mins before the special ended! I heard they do that a lot here so be warned.\n",
      "Standard Clean: ['Dirt', 'cheap', 'happy', 'hour', 'specials', '.', 'Half', 'priced', 'drinks', '.', 'really', 'crowd', '.', 'Lots', 'college', 'kids', 'Saturday', 'night', '.', 'hand', 'lots', 'hot', 'girls', '.', 'YEAAAHHH', 'buddy', '!', \"'ll\", 'get', 'point', '.', 'hard', 'really', 'try', 'turn', 'place', 'club', 'nights', 'still', 'always', 'tavern', '.', 'bartender', 'nice', 'charged', 'full', 'price', 'drinks', '5-10', 'mins', 'special', 'ended', '!', 'heard', 'lot', 'warned', '.']\n",
      "Keep Negation : ['Dirt', 'cheap', 'happy', 'hour', 'specials', '.', 'Half', 'priced', 'drinks', '.', 'Not', 'really', 'crowd', '.', 'Lots', 'college', 'kids', 'Saturday', 'night', '.', 'hand', 'lots', 'hot', 'girls', '.', 'YEAAAHHH', 'buddy', '!', \"'ll\", 'get', 'point', '.', 'hard', 'really', 'try', 'turn', 'place', 'club', 'nights', 'still', 'always', 'tavern', '.', 'bartender', 'nice', 'charged', 'full', 'price', 'drinks', '5-10', 'mins', 'special', 'ended', '!', 'heard', 'lot', 'warned', '.']\n",
      "\n",
      "Texte Original: Unbelievably poor customer \"service\". Beyond bad. They insisted on charging me a large car price to wash my mid-size car. I was told to go talk to Don Risdon, and when I did, his first reaction was to physically shove me and tell me to get away from him before he really lost his temper. Can you believe that? Never in my 50 years have I encountered anything like it. He would not acknowledge that he was misleading customers by the prices posted at the cash register.\n",
      "Standard Clean: ['Unbelievably', 'poor', 'customer', '``', 'service', \"''\", '.', 'Beyond', 'bad', '.', 'insisted', 'charging', 'large', 'car', 'price', 'wash', 'mid-size', 'car', '.', 'told', 'go', 'talk', 'Risdon', ',', ',', 'first', 'reaction', 'physically', 'shove', 'tell', 'get', 'away', 'really', 'lost', 'temper', '.', 'believe', '?', 'Never', '50', 'years', 'encountered', 'anything', 'like', '.', 'would', 'acknowledge', 'misleading', 'customers', 'prices', 'posted', 'cash', 'register', '.']\n",
      "Keep Negation : ['Unbelievably', 'poor', 'customer', '``', 'service', \"''\", '.', 'Beyond', 'bad', '.', 'insisted', 'charging', 'large', 'car', 'price', 'wash', 'mid-size', 'car', '.', 'told', 'go', 'talk', 'Risdon', ',', ',', 'first', 'reaction', 'physically', 'shove', 'tell', 'get', 'away', 'really', 'lost', 'temper', '.', 'believe', '?', 'Never', '50', 'years', 'encountered', 'anything', 'like', '.', 'would', 'not', 'acknowledge', 'misleading', 'customers', 'prices', 'posted', 'cash', 'register', '.']\n",
      "\n",
      "Texte Original: I walked in the door and was greeted with a welcoming smile. I was offered help in finding a good match for my home. I was told if I didn't like it, they would return my money - no problem. A very nice experience and fair pricing.\n",
      "Standard Clean: ['walked', 'door', 'greeted', 'welcoming', 'smile', '.', 'offered', 'help', 'finding', 'good', 'match', 'home', '.', 'told', \"n't\", 'like', ',', 'would', 'return', 'money', '-', 'problem', '.', 'nice', 'experience', 'fair', 'pricing', '.']\n",
      "Keep Negation : ['walked', 'door', 'greeted', 'welcoming', 'smile', '.', 'offered', 'help', 'finding', 'good', 'match', 'home', '.', 'told', \"n't\", 'like', ',', 'would', 'return', 'money', '-', 'no', 'problem', '.', 'nice', 'experience', 'fair', 'pricing', '.']\n",
      "\n",
      "Texte Original: Nothing beats pizza and beer in my book. This place nails both, with an eye towards sustainability which always makes me feel good. They have a specially brewed beer, and a handful of other craft beers on tap to satisfy almost any taste. I prefer the deep dish, although my accomplice likes the thin crust more. That usually just means leftovers. I wish their appetizers were more adventurous, or changed at all, but I guess don't mess with success and they're a pizza place both apply. I just wish they delivered.\n",
      "Standard Clean: ['Nothing', 'beats', 'pizza', 'beer', 'book', '.', 'place', 'nails', ',', 'eye', 'towards', 'sustainability', 'always', 'makes', 'feel', 'good', '.', 'specially', 'brewed', 'beer', ',', 'handful', 'craft', 'beers', 'tap', 'satisfy', 'almost', 'taste', '.', 'prefer', 'deep', 'dish', ',', 'although', 'accomplice', 'likes', 'thin', 'crust', '.', 'usually', 'means', 'leftovers', '.', 'wish', 'appetizers', 'adventurous', ',', 'changed', ',', 'guess', \"n't\", 'mess', 'success', \"'re\", 'pizza', 'place', 'apply', '.', 'wish', 'delivered', '.']\n",
      "Keep Negation : ['Nothing', 'beats', 'pizza', 'beer', 'book', '.', 'place', 'nails', ',', 'eye', 'towards', 'sustainability', 'always', 'makes', 'feel', 'good', '.', 'specially', 'brewed', 'beer', ',', 'handful', 'craft', 'beers', 'tap', 'satisfy', 'almost', 'taste', '.', 'prefer', 'deep', 'dish', ',', 'although', 'accomplice', 'likes', 'thin', 'crust', '.', 'usually', 'means', 'leftovers', '.', 'wish', 'appetizers', 'adventurous', ',', 'changed', ',', 'guess', \"n't\", 'mess', 'success', \"'re\", 'pizza', 'place', 'apply', '.', 'wish', 'delivered', '.']\n"
     ]
    }
   ],
   "source": [
    "# Find examples containing negation words\n",
    "neg_examples = reviews[reviews['text'].str.contains('not|no ', case=False, na=False)].head(5)\n",
    "\n",
    "for idx, row in neg_examples.iterrows():\n",
    "    print(f\"\\nTexte Original: {row['text']}\")\n",
    "    print(f\"Standard Clean: {row['tokens_clean_standard']}\")\n",
    "    print(f\"Keep Negation : {row['tokens_clean_negation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistiques de Réduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T08:45:54.614972Z",
     "iopub.status.busy": "2026-02-06T08:45:54.614972Z",
     "iopub.status.idle": "2026-02-06T08:45:54.628979Z",
     "shell.execute_reply": "2026-02-06T08:45:54.628339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre moyen de tokens (original): 118.3\n",
      "Nombre moyen de tokens (apres stopwords): 68.1\n",
      "Réduction de taille: 42.4%\n"
     ]
    }
   ],
   "source": [
    "reviews['count_original'] = reviews['tokens'].apply(len)\n",
    "reviews['count_clean'] = reviews['tokens_clean_negation'].apply(len)\n",
    "\n",
    "avg_orig = reviews['count_original'].mean()\n",
    "avg_clean = reviews['count_clean'].mean()\n",
    "reduction = (avg_orig - avg_clean) / avg_orig * 100\n",
    "\n",
    "print(f\"Nombre moyen de tokens (original): {avg_orig:.1f}\")\n",
    "print(f\"Nombre moyen de tokens (apres stopwords): {avg_clean:.1f}\")\n",
    "print(f\"Réduction de taille: {reduction:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

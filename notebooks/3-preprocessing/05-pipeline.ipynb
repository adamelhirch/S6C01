{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Preprocessing Complet\n",
    "\n",
    "Objectif: Appliquer et tester la fonction `preprocess_pipeline` qui regroupe toutes les étapes.\n",
    "\n",
    "Partie de la story **SAE-74**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T08:53:39.618218Z",
     "iopub.status.busy": "2026-02-06T08:53:39.618218Z",
     "iopub.status.idle": "2026-02-06T08:53:41.003665Z",
     "shell.execute_reply": "2026-02-06T08:53:41.002983Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\melou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\melou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\melou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\melou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.abspath(os.path.join('../..', 'src')))\n",
    "\n",
    "from text_preprocessing import preprocess_pipeline\n",
    "\n",
    "# Download NLTK resources (ensure everything is there)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Enable tqdm for pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests Unitaires Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T08:53:41.020709Z",
     "iopub.status.busy": "2026-02-06T08:53:41.020709Z",
     "iopub.status.idle": "2026-02-06T08:53:43.566814Z",
     "shell.execute_reply": "2026-02-06T08:53:43.566814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: The food was AMAZING! I did not like the service at all.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Defaults: ['food', 'amazing', 'like', 'service']\n",
      "Keep Stopwords: ['the', 'food', 'wa', 'amazing', 'i', 'did', 'not', 'like', 'the', 'service', 'at', 'all']\n",
      "Keep Negation: ['food', 'amazing', 'not', 'like', 'service']\n",
      "No Lemma: ['food', 'amazing', 'like', 'service']\n"
     ]
    }
   ],
   "source": [
    "test_text = \"The food was AMAZING! I did not like the service at all.\"\n",
    "\n",
    "print(f\"Original: {test_text}\\n\")\n",
    "\n",
    "# 1. Full Pipeline\n",
    "res1 = preprocess_pipeline(test_text)\n",
    "print(f\"Full Defaults: {res1}\")\n",
    "\n",
    "# 2. No Stopword Removal\n",
    "res2 = preprocess_pipeline(test_text, remove_stopwords_flag=False)\n",
    "print(f\"Keep Stopwords: {res2}\")\n",
    "\n",
    "# 3. Keep Negation\n",
    "res3 = preprocess_pipeline(test_text, exclude_stopwords={'not', 'no'})\n",
    "print(f\"Keep Negation: {res3}\")\n",
    "\n",
    "# 4. No Lemmatization\n",
    "res4 = preprocess_pipeline(test_text, lemmatize_flag=False)\n",
    "print(f\"No Lemma: {res4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application au Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T08:53:43.568994Z",
     "iopub.status.busy": "2026-02-06T08:53:43.568994Z",
     "iopub.status.idle": "2026-02-06T08:53:47.230571Z",
     "shell.execute_reply": "2026-02-06T08:53:47.229536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sample of 2000 reviews\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 225/2000 [00:00<00:00, 2236.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 459/2000 [00:00<00:00, 2284.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 688/2000 [00:00<00:00, 2163.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 908/2000 [00:00<00:00, 2162.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▋    | 1125/2000 [00:00<00:00, 2161.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 1353/2000 [00:00<00:00, 2193.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▊  | 1573/2000 [00:00<00:00, 2033.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 1820/2000 [00:00<00:00, 2157.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 2000/2000 [00:00<00:00, 2181.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Went for lunch and found that my burger was me...</td>\n",
       "      <td>[went, lunch, found, burger, meh, obvious, foc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I needed a new tires for my wife's car. They h...</td>\n",
       "      <td>[needed, new, tire, wife, car, special, order,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jim Woltman who works at Goleta Honda is 5 sta...</td>\n",
       "      <td>[jim, woltman, work, goleta, honda, 5, star, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Been here a few times to get some shrimp. They...</td>\n",
       "      <td>[time, get, shrimp, theyve, got, nice, selecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is one fantastic place to eat whether you...</td>\n",
       "      <td>[one, fantastic, place, eat, whether, hungry, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Went for lunch and found that my burger was me...   \n",
       "1  I needed a new tires for my wife's car. They h...   \n",
       "2  Jim Woltman who works at Goleta Honda is 5 sta...   \n",
       "3  Been here a few times to get some shrimp. They...   \n",
       "4  This is one fantastic place to eat whether you...   \n",
       "\n",
       "                                        tokens_final  \n",
       "0  [went, lunch, found, burger, meh, obvious, foc...  \n",
       "1  [needed, new, tire, wife, car, special, order,...  \n",
       "2  [jim, woltman, work, goleta, honda, 5, star, k...  \n",
       "3  [time, get, shrimp, theyve, got, nice, selecti...  \n",
       "4  [one, fantastic, place, eat, whether, hungry, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load cleaned reviews and use Sample\n",
    "reviews_path = '../../data/cleaned/reviews_clean.parquet'\n",
    "if os.path.exists(reviews_path):\n",
    "    reviews = pd.read_parquet(reviews_path)\n",
    "    reviews = reviews.head(2000).copy()\n",
    "    print(\"Using sample of 2000 reviews\")\n",
    "else:\n",
    "    reviews = pd.DataFrame({'text': [\"Sample review text.\", \"Another review here.\"]})\n",
    "\n",
    "print(\"Processing...\")\n",
    "# Apply pipeline (Stopwords removed, Negation Kept)\n",
    "reviews['tokens_final'] = reviews['text'].progress_apply(\n",
    "    lambda x: preprocess_pipeline(x, exclude_stopwords={'not', 'no', 'nor', 'neither'})\n",
    ")\n",
    "\n",
    "reviews[['text', 'tokens_final']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T08:53:47.233078Z",
     "iopub.status.busy": "2026-02-06T08:53:47.232552Z",
     "iopub.status.idle": "2026-02-06T08:53:47.259765Z",
     "shell.execute_reply": "2026-02-06T08:53:47.259765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ../../outputs/reviews_preprocessed.pkl\n"
     ]
    }
   ],
   "source": [
    "output_path = '../../outputs/reviews_preprocessed.pkl'\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "reviews.to_pickle(output_path)\n",
    "print(f\"Saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
